{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PeerSync A fast, secure, and decentralized container registry, optimized for edge computing. Features OCI-compliant interface for non-intrusive integration with existing workflow Minimal configuration Fully federated design that enables zero-management operation Algorithms that efficiently utilize local resources High performance and low container startup latency Support for multiple architectures Objectives With edge computing, devices are often deployed in remote locations with limited resource capacity (network, storage, compute, etc. ), and the reliability of aforementioned resources is less than that of traditional data centers. Yet, the demand for using edge devices to run containerized applications, including AI/ML workloads, is increasing. PeerSync aims to provide a seamless solution that accelerates the deployment of containers to edge devices and minimizes resource costs. Usage Please refer to the Get Started page for detailed instructions, and Configuration configuration options. Internals For the technical details of PeerSync , please refer to the Internals page for the architecture and design. Demo A quick demo of PeerSync in action:","title":"PeerSync"},{"location":"#peersync","text":"A fast, secure, and decentralized container registry, optimized for edge computing.","title":"PeerSync"},{"location":"#features","text":"OCI-compliant interface for non-intrusive integration with existing workflow Minimal configuration Fully federated design that enables zero-management operation Algorithms that efficiently utilize local resources High performance and low container startup latency Support for multiple architectures","title":"Features"},{"location":"#objectives","text":"With edge computing, devices are often deployed in remote locations with limited resource capacity (network, storage, compute, etc. ), and the reliability of aforementioned resources is less than that of traditional data centers. Yet, the demand for using edge devices to run containerized applications, including AI/ML workloads, is increasing. PeerSync aims to provide a seamless solution that accelerates the deployment of containers to edge devices and minimizes resource costs.","title":"Objectives"},{"location":"#usage","text":"Please refer to the Get Started page for detailed instructions, and Configuration configuration options.","title":"Usage"},{"location":"#internals","text":"For the technical details of PeerSync , please refer to the Internals page for the architecture and design.","title":"Internals"},{"location":"#demo","text":"A quick demo of PeerSync in action:","title":"Demo"},{"location":"configuration/","text":"Configuration The configuration file is in YAML format. Here is the example file with explanations: node_name: \"node1\" listen: - \"127.0.0.1:23333\" - \"[::1]:23333\" bootstrap: - node_name: \"node0\" addr: \"127.0.0.1:10086\" docker_socket: \"/var/run/docker.sock\" docker_registry: \"http://127.0.0.1:5000\" cache_directory: \"cache1\" node_name : The name of the node. It is used to identify the node in the network. Should be unique and human-readable for easier management. listen : The list of addresses to listen on. It is a list of strings in the format of IP:PORT . The address can be IPv4 or IPv6. This address is used for both registry and peer-to-peer communication. bootstrap : The list of bootstrap nodes. It is a list of objects with node_name and addr fields. node_name is the name of the node, and addr is the address of the node in the format of IP:PORT . This list of nodes will be contacted on startup to join the network. In addition, to accelerate the bootstrap process, any node that is reachable within the same LAN will also be included. docker_socket : The path to the Docker socket. It is used to communicate with the Docker daemon to collect required information at runtime. PeerSync must have the necessary permissions to access the Docker socket. docker_registry : The address of the upstream Docker registry. It is used to pull images that are not available locally or from other peers. The address should be in the format of http://IP:PORT . cache_directory : The directory to store the cached images. It is used to store images that are pulled from the upstream Docker registry or other peers. The directory should be writable by the PeerSync process. Additionally, it is possible to specify -v[v...] to the commandline arguments to increase the verbosity of the logs. This is useful for debugging purposes.","title":"Configuration"},{"location":"configuration/#configuration","text":"The configuration file is in YAML format. Here is the example file with explanations: node_name: \"node1\" listen: - \"127.0.0.1:23333\" - \"[::1]:23333\" bootstrap: - node_name: \"node0\" addr: \"127.0.0.1:10086\" docker_socket: \"/var/run/docker.sock\" docker_registry: \"http://127.0.0.1:5000\" cache_directory: \"cache1\" node_name : The name of the node. It is used to identify the node in the network. Should be unique and human-readable for easier management. listen : The list of addresses to listen on. It is a list of strings in the format of IP:PORT . The address can be IPv4 or IPv6. This address is used for both registry and peer-to-peer communication. bootstrap : The list of bootstrap nodes. It is a list of objects with node_name and addr fields. node_name is the name of the node, and addr is the address of the node in the format of IP:PORT . This list of nodes will be contacted on startup to join the network. In addition, to accelerate the bootstrap process, any node that is reachable within the same LAN will also be included. docker_socket : The path to the Docker socket. It is used to communicate with the Docker daemon to collect required information at runtime. PeerSync must have the necessary permissions to access the Docker socket. docker_registry : The address of the upstream Docker registry. It is used to pull images that are not available locally or from other peers. The address should be in the format of http://IP:PORT . cache_directory : The directory to store the cached images. It is used to store images that are pulled from the upstream Docker registry or other peers. The directory should be writable by the PeerSync process. Additionally, it is possible to specify -v[v...] to the commandline arguments to increase the verbosity of the logs. This is useful for debugging purposes.","title":"Configuration"},{"location":"evaluation/","text":"Evaluation Docker-based Evaluation For easy evaluation, we provide the details of our Docker Compose-based evaluation configuration. First, we create a few Docker networks. One network will be for the registry, and others are for PeerSync workers. $ docker network create --subnet=172.30.1.0/24 --gateway=172.30.1.1 --ipv6 --subnet=2001:db8:1::/48 --gateway 2001:db8::1 lan1 ... To correctly route traffic between the networks and emulate a multi-network environment, we cannot rely on the default router in each Docker network, because we cannot configure their behaviors. Instead, we create a few routers in each network. Here is an example: services: router1: image: router container_name: router1 cap_add: - NET_ADMIN entrypoint: /bin/sh command: > -c \"ip route add 172.30.2.253 dev eth1 && ... ip route change 172.30.2.0/24 via 172.30.2.253 dev eth1 && ... tail -f /dev/null\" sysctls: - net.ipv4.conf.all.src_valid_mark=1 - net.ipv4.conf.all.forwarding=1 - net.ipv6.conf.all.forwarding=1 networks: lan1: ipv4_address: 172.30.1.254 ... For brevity, we omit the IPv6 configuration, which is not necessary for evaluation. However, in production deployments, we recommend enabling IPv6 where possible for more robust networking. Then, we configure the route for other networks on each worker: sudo ip route add 172.30.0.0/16 via 172.30.1.254 dev eth0 To configure bandwidth limit, packet loss, and latency between different networks, tc(8) can be used: sudo tc qdisc add dev eth0 root handle 1: tbf rate 100mbit burst 32kbit latency 400ms && sudo tc qdisc add dev eth0 parent 1: handle 10: netem loss 1% delay 50ms && After startup, PeerSync should start listening on the port configured immediately. At this stage, it is ready to receive requests, functioning similarly to any standard registry.","title":"Evaluation"},{"location":"evaluation/#evaluation","text":"","title":"Evaluation"},{"location":"evaluation/#docker-based-evaluation","text":"For easy evaluation, we provide the details of our Docker Compose-based evaluation configuration. First, we create a few Docker networks. One network will be for the registry, and others are for PeerSync workers. $ docker network create --subnet=172.30.1.0/24 --gateway=172.30.1.1 --ipv6 --subnet=2001:db8:1::/48 --gateway 2001:db8::1 lan1 ... To correctly route traffic between the networks and emulate a multi-network environment, we cannot rely on the default router in each Docker network, because we cannot configure their behaviors. Instead, we create a few routers in each network. Here is an example: services: router1: image: router container_name: router1 cap_add: - NET_ADMIN entrypoint: /bin/sh command: > -c \"ip route add 172.30.2.253 dev eth1 && ... ip route change 172.30.2.0/24 via 172.30.2.253 dev eth1 && ... tail -f /dev/null\" sysctls: - net.ipv4.conf.all.src_valid_mark=1 - net.ipv4.conf.all.forwarding=1 - net.ipv6.conf.all.forwarding=1 networks: lan1: ipv4_address: 172.30.1.254 ... For brevity, we omit the IPv6 configuration, which is not necessary for evaluation. However, in production deployments, we recommend enabling IPv6 where possible for more robust networking. Then, we configure the route for other networks on each worker: sudo ip route add 172.30.0.0/16 via 172.30.1.254 dev eth0 To configure bandwidth limit, packet loss, and latency between different networks, tc(8) can be used: sudo tc qdisc add dev eth0 root handle 1: tbf rate 100mbit burst 32kbit latency 400ms && sudo tc qdisc add dev eth0 parent 1: handle 10: netem loss 1% delay 50ms && After startup, PeerSync should start listening on the port configured immediately. At this stage, it is ready to receive requests, functioning similarly to any standard registry.","title":"Docker-based Evaluation"},{"location":"get_started/","text":"Get Started This page will help you deploy PeerSync to your environment. Prerequisites One or more machines running Linux and Docker Direct network access between machines Rust nightly toolchain Building To start the building process, the source code repository should first be cloned to a local device. Given that PeerSync is developed in Rust, setting up a Rust environment is a prerequisite. The recommended approach for deploying Rust is through https://rustup.rs/ , which simplifies the installation process. Although our demonstration is conducted on a fresh Debian installation on an x86_64 architecture, the procedure is applicable to other operating systems with appropriate configurations. The next step involves preparing the compilation target. Designed for edge devices, PeerSync is compiled as a statically linked binary file, eliminating the need for external dependencies. To enhance portability across various platforms, we link the program with musl , a widely compatible C library implementation. It is important to note that, as of Rust 1.8.2, PeerSync requires the nightly Rust toolchain for utilizing several unstable features. Therefore, part of the installation process will involve setting up the nightly toolchain. This ensures that PeerSync is built with the latest features and optimizations offered by Rust, aligning with the system's cutting-edge and performance-oriented design. $ sudo apt update $ sudo apt install musl musl-dev musl-tools $ rustup target add x86_64-unknown-linux-musl $ rustup toolchain install nightly Now, we can proceed with building. For convenient evaluation, we can additionally create a Docker image for later use. $ cargo build --release --target x86_64-unknown-linux-musl $ docker build . -t peersync PeerSync is ready for deployment. It is also necessary to update the configuration file according to the actual values. The configuration file is a YAML file, and an example can be found at ./config_example.yaml . Running Before running PeerSync , an valid configuration file is required. A configuration file is a YAML file, please refer to the Configuration page for details. Here, we assume the configuration file is located at /etc/peersync.yaml . PeerSync is meant to be run as a daemon process. There are multiple ways to achieve this, and we will demonstrate two ways: using systemd or Docker. Systemd First, copy the built binary to a PATH directory, such as /usr/local/bin/peersync : $ sudo cp target/x86_64-unknown-linux-musl/release/peersync /usr/local/bin/peersync Next, we set up a systemd service: $ sudo tee /etc/systemd/system/peersync.service <<EOF [Unit] Description=PeerSync After=network.target [Service] Type=simple ExecStart=/usr/local/bin/peersync -c /etc/peersync.yaml Restart=always RestartSec=5 [Install] WantedBy=multi-user.target EOF Finally, start and enable the service: $ sudo systemctl daemon-reload $ sudo systemctl start peersync Docker We have created a Docker image when building PeerSync . To run PeerSync in a Docker container, we can use the following command: $ docker run -d --name peersync -p $PORT -v /etc/peersync.yaml:/etc/peersync.yaml peersync Replace $PORT with the port number you want to expose. The configuration file is mounted to /etc/peersync.yaml in the container. After starting PeerSync , you can modify the default registry used by Docker to point to PeerSync : $ sudo vim /etc docker/daemon.json $ sudo systemctl restart docker","title":"Get Started"},{"location":"get_started/#get-started","text":"This page will help you deploy PeerSync to your environment.","title":"Get Started"},{"location":"get_started/#prerequisites","text":"One or more machines running Linux and Docker Direct network access between machines Rust nightly toolchain","title":"Prerequisites"},{"location":"get_started/#building","text":"To start the building process, the source code repository should first be cloned to a local device. Given that PeerSync is developed in Rust, setting up a Rust environment is a prerequisite. The recommended approach for deploying Rust is through https://rustup.rs/ , which simplifies the installation process. Although our demonstration is conducted on a fresh Debian installation on an x86_64 architecture, the procedure is applicable to other operating systems with appropriate configurations. The next step involves preparing the compilation target. Designed for edge devices, PeerSync is compiled as a statically linked binary file, eliminating the need for external dependencies. To enhance portability across various platforms, we link the program with musl , a widely compatible C library implementation. It is important to note that, as of Rust 1.8.2, PeerSync requires the nightly Rust toolchain for utilizing several unstable features. Therefore, part of the installation process will involve setting up the nightly toolchain. This ensures that PeerSync is built with the latest features and optimizations offered by Rust, aligning with the system's cutting-edge and performance-oriented design. $ sudo apt update $ sudo apt install musl musl-dev musl-tools $ rustup target add x86_64-unknown-linux-musl $ rustup toolchain install nightly Now, we can proceed with building. For convenient evaluation, we can additionally create a Docker image for later use. $ cargo build --release --target x86_64-unknown-linux-musl $ docker build . -t peersync PeerSync is ready for deployment. It is also necessary to update the configuration file according to the actual values. The configuration file is a YAML file, and an example can be found at ./config_example.yaml .","title":"Building"},{"location":"get_started/#running","text":"Before running PeerSync , an valid configuration file is required. A configuration file is a YAML file, please refer to the Configuration page for details. Here, we assume the configuration file is located at /etc/peersync.yaml . PeerSync is meant to be run as a daemon process. There are multiple ways to achieve this, and we will demonstrate two ways: using systemd or Docker.","title":"Running"},{"location":"get_started/#systemd","text":"First, copy the built binary to a PATH directory, such as /usr/local/bin/peersync : $ sudo cp target/x86_64-unknown-linux-musl/release/peersync /usr/local/bin/peersync Next, we set up a systemd service: $ sudo tee /etc/systemd/system/peersync.service <<EOF [Unit] Description=PeerSync After=network.target [Service] Type=simple ExecStart=/usr/local/bin/peersync -c /etc/peersync.yaml Restart=always RestartSec=5 [Install] WantedBy=multi-user.target EOF Finally, start and enable the service: $ sudo systemctl daemon-reload $ sudo systemctl start peersync","title":"Systemd"},{"location":"get_started/#docker","text":"We have created a Docker image when building PeerSync . To run PeerSync in a Docker container, we can use the following command: $ docker run -d --name peersync -p $PORT -v /etc/peersync.yaml:/etc/peersync.yaml peersync Replace $PORT with the port number you want to expose. The configuration file is mounted to /etc/peersync.yaml in the container. After starting PeerSync , you can modify the default registry used by Docker to point to PeerSync : $ sudo vim /etc docker/daemon.json $ sudo systemctl restart docker","title":"Docker"},{"location":"internals/","text":"Internals This page describes the design and implementation details of PeerSync . Motivation There are two major points of motivation for PeerSync : - Use local where possible to reduce latency and uplink bandwidth usage. - Enable self-healing and self-organizing swarm for easy deployment and management. These two points are based on the resource-constrained and unreliable nature of edge devices, and the observation that the current P2P-based systems are not optimized for these environment settings. Architecture In PeerSync , we implemented a P2P network from scrach, focusing on using runtime metrics to optimize traffic scheduling. While there are multiple points of optimization, the most important one is to keep traffic local (i.e. within the same layer 2 network) as much as possible. The tracker system is similar to the one used in BitTorrent, but with election functionality to ensure a tracker is always available without human intervention. The caching system uses a special popularity-based algorithm to keep the most popular images in the local network, so they can be quickly shared even if one peer no longer has the it. Finally, all the complex logic is hidden behind a simple OCI-compliant interface, enabling easy integration with existing workflows.","title":"Internals"},{"location":"internals/#internals","text":"This page describes the design and implementation details of PeerSync .","title":"Internals"},{"location":"internals/#motivation","text":"There are two major points of motivation for PeerSync : - Use local where possible to reduce latency and uplink bandwidth usage. - Enable self-healing and self-organizing swarm for easy deployment and management. These two points are based on the resource-constrained and unreliable nature of edge devices, and the observation that the current P2P-based systems are not optimized for these environment settings.","title":"Motivation"},{"location":"internals/#architecture","text":"In PeerSync , we implemented a P2P network from scrach, focusing on using runtime metrics to optimize traffic scheduling. While there are multiple points of optimization, the most important one is to keep traffic local (i.e. within the same layer 2 network) as much as possible. The tracker system is similar to the one used in BitTorrent, but with election functionality to ensure a tracker is always available without human intervention. The caching system uses a special popularity-based algorithm to keep the most popular images in the local network, so they can be quickly shared even if one peer no longer has the it. Finally, all the complex logic is hidden behind a simple OCI-compliant interface, enabling easy integration with existing workflows.","title":"Architecture"}]}